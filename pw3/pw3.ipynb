{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba7dc16-489f-4a3e-9cec-ab1b054719f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_set = pd.read_csv('employee.csv', encoding='ISO-8859-1')\n",
    "# travailler sur une copie pour faire des comparaisons\n",
    "df = data_set.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15c68ac-1058-4078-9769-36ce96146bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Calcule le nombre de valeurs manquantes selon chaque feature\n",
    "# fonction old-school, existe certainement une fonction chez pandas...\n",
    "def compute_missing_values(df):\n",
    "    list_missing_val = {}\n",
    "    col = df.columns\n",
    "    for i, k in enumerate(col):\n",
    "        list_missing_val[k] = df[k].isna().sum()\n",
    "    return list_missing_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da4df011-3f9f-4618-a9e2-0e651e942445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_box_plots(df, col):\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(35, 35))\n",
    "    axs = axs.flatten()\n",
    "    for i, col in enumerate(col):\n",
    "        sns.boxplot(y=df[col], data=df, ax=axs[i])\n",
    "    \n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "    fig.delaxes(axs[-1])\n",
    "    fig.delaxes(axs[-2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "557d932b-bbce-4349-878b-bdab98b14f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22552, 12)\n",
      "missing values\n",
      "NAME-->6\n",
      "DEPARTMENT_NAME-->6\n",
      "TITLE-->6\n",
      "REGULAR-->644\n",
      "RETRO-->22150\n",
      "OTHER-->8423\n",
      "OVERTIME-->15706\n",
      "INJURED-->21096\n",
      "DETAIL-->20493\n",
      "QUINN_EDUCATION_INCENTIVE-->21166\n",
      "TOTAL_GROSS-->6\n",
      "POSTAL-->6\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Q2 voici la taille du dataframe:\n",
    "print(df.shape)\n",
    "# Q2 voici les valeurs manquantes selon les colonnes:\n",
    "list = compute_missing_values(data_set)\n",
    "print(\"missing values\")\n",
    "for i in list:\n",
    "    print(f\"{i}-->{list[i]:d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b33adcf6-8d0a-4d06-b582-6fb4b8d85d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22546 entries, 0 to 22545\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   NAME                       22546 non-null  object\n",
      " 1   DEPARTMENT_NAME            22546 non-null  object\n",
      " 2   TITLE                      22546 non-null  object\n",
      " 3   REGULAR                    21908 non-null  object\n",
      " 4   RETRO                      402 non-null    object\n",
      " 5   OTHER                      14129 non-null  object\n",
      " 6   OVERTIME                   6846 non-null   object\n",
      " 7   INJURED                    1456 non-null   object\n",
      " 8   DETAIL                     2059 non-null   object\n",
      " 9   QUINN_EDUCATION_INCENTIVE  1386 non-null   object\n",
      " 10  TOTAL_GROSS                22546 non-null  object\n",
      " 11  POSTAL                     22546 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compte le nombre de tuples vides (toutes les features à nan)\n",
    "# df[df.isna().all(axis=1)].shape[0]\n",
    "\n",
    "# suppression des tuples vides (toutes les colonnes à NaN)\n",
    "df = df.dropna(how='all')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2ef285-d03e-4d40-9046-91d46318c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['REGULAR', 'RETRO', 'OTHER', 'OVERTIME', 'INJURED', 'DETAIL', \n",
    "       'QUINN_EDUCATION_INCENTIVE', 'TOTAL_GROSS', 'POSTAL']\n",
    "# on remplace les , ' ou tout les trucs qui perturbent la convertion en float python.\n",
    "df[col] = df[col].replace({',': '', \"'\": ''}, regex=True)\n",
    "# on applique la converton en float\n",
    "df[col] = df[col].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a99c6a-dc56-4750-8c84-4a316069ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# on afficher les boxplots des features numériques pour observer à quoi cela ressemble\n",
    "col = ['REGULAR', 'RETRO', 'OTHER', 'OVERTIME', 'INJURED', 'DETAIL', 'QUINN_EDUCATION_INCENTIVE', 'TOTAL_GROSS']\n",
    "\n",
    "# show_box_plots(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "321df34f-f8c4-4c97-bc47-8fa98c5c3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous séléctionnons les tuples comprenant les 5 valeurs max sur le total_gross\n",
    "# nous avons 2 tuples que nous supprimons.\n",
    "top = df.nlargest(n=2, columns=['TOTAL_GROSS']).index\n",
    "# Supprimer les lignes correspondant aux index obtenus\n",
    "df = df.drop(top)\n",
    "#show_box_plots(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0908574-9a38-42e8-aab5-d681b758b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['REGULAR', 'RETRO', 'OTHER', 'OVERTIME', 'INJURED', 'DETAIL', 'QUINN_EDUCATION_INCENTIVE', 'TOTAL_GROSS']\n",
    "target = df['DEPARTMENT_NAME']\n",
    "df = df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "657992e4-639f-49b4-9b3f-73ac0c1e0363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputer: Zero\n",
      "Classifier: KNN         , F1 (micro): 0.231, F1 (macro): 0.050, accuracy: 0.231\n",
      "Classifier: DecisionTree, F1 (micro): 0.260, F1 (macro): 0.064, accuracy: 0.260\n",
      "Classifier: RandomForest, F1 (micro): 0.284, F1 (macro): 0.075, accuracy: 0.284\n",
      "Imputer: Median\n",
      "Classifier: KNN         , F1 (micro): 0.234, F1 (macro): 0.051, accuracy: 0.234\n",
      "Classifier: DecisionTree, F1 (micro): 0.264, F1 (macro): 0.068, accuracy: 0.264\n",
      "Classifier: RandomForest, F1 (micro): 0.282, F1 (macro): 0.073, accuracy: 0.282\n",
      "Imputer: KNN\n",
      "Classifier: KNN         , F1 (micro): 0.228, F1 (macro): 0.051, accuracy: 0.228\n",
      "Classifier: DecisionTree, F1 (micro): 0.235, F1 (macro): 0.056, accuracy: 0.235\n",
      "Classifier: RandomForest, F1 (micro): 0.266, F1 (macro): 0.065, accuracy: 0.266\n",
      "Imputer: Iterative\n",
      "Classifier: KNN         , F1 (micro): 0.238, F1 (macro): 0.051, accuracy: 0.238\n",
      "Classifier: DecisionTree, F1 (micro): 0.254, F1 (macro): 0.072, accuracy: 0.254\n",
      "Classifier: RandomForest, F1 (micro): 0.268, F1 (macro): 0.066, accuracy: 0.268\n",
      "Dummy time -> f1 micro: 0.139, f1 macro: 0.001, accuracy: 0.139\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.1, random_state=42)\n",
    "\n",
    "# Imputation des valeurs manquantes\n",
    "imputers = {\n",
    "    \"Zero\": SimpleImputer(strategy=\"constant\", fill_value=0),\n",
    "    \"Median\": SimpleImputer(strategy=\"median\"),\n",
    "    \"KNN\": KNNImputer(),\n",
    "    \"Iterative\": IterativeImputer()\n",
    "}\n",
    "\n",
    "imputed_data_train = {}\n",
    "imputed_data_test = {}\n",
    "\n",
    "for imputer_name, imputer in imputers.items():\n",
    "    # Imputer sur les données d'entraînement\n",
    "    X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "    imputed_data_train[imputer_name] = X_train_imputed\n",
    "    \n",
    "    # Imputer sur les données de test\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "    imputed_data_test[imputer_name] = X_test_imputed\n",
    "\n",
    "classifiers = {\n",
    "    \"KNN         \": KNeighborsClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for imputer_name in imputers.keys():\n",
    "    print(f\"Imputer: {imputer_name}\")\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(imputed_data_train[imputer_name], y_train)\n",
    "        \n",
    "        y_pred = clf.predict(imputed_data_test[imputer_name])\n",
    "        \n",
    "        f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        accu = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Classifier: {clf_name}, F1 (micro): {f1_micro:.3f}, F1 (macro): {f1_macro:.3f}, accuracy: {accu:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "\n",
    "accu_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "f1_dummy_mi = f1_score(y_test, y_pred_dummy, average='micro')\n",
    "f1_dummy_ma = f1_score(y_test, y_pred_dummy, average='macro')\n",
    "print(f\"Dummy time -> f1 micro: {f1_dummy_mi:.3f}, f1 macro: {f1_dummy_ma:.3f}, accuracy: {accu_dummy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30f541-d76b-4605-a929-bab1da1fa84c",
   "metadata": {},
   "source": [
    "# Rapport\n",
    "\n",
    "## Q6\n",
    "Selon doc scikit learn -> incompatible avec les classificateurs\n",
    "Selon GTP -> oui \n",
    "\n",
    "\n",
    "## Q7:\n",
    "\n",
    "- b) Si on attribue à tous les items la classe majoritaire, alors le F1-score sera simplement égal à 0 pour toutes les classes minoritaires, car il n'y aura aucun vrai positif (TP), et donc le rappel (recall) et la précision (precision) seront tous deux nuls pour ces classes.\n",
    "\n",
    "    Cependant, pour la classe majoritaire, le F1-score sera déterminé par la précision et le rappel pour cette classe. Comme toutes les prédictions seront corrects pour la classe majoritaire, la précision sera égale à 1 et le rappel sera également égal à 1.\n",
    "\n",
    "    Ainsi, le F1-score pour toutes les classes sera égal à 1 dans ce scénario où toutes les observations sont attribuées à la classe majoritaire.\n",
    "\n",
    "- c) Dans notre cas la combinaison qui a la meilleure combinaison semble être celle avec le classificateur random forest avec la méthode d'imputation avec la médiane ou zéro.\n",
    "\n",
    "- d) Les scores F1 avec micro-moyenne sont souvent plus élevés que ceux calculés avec une macro-moyenne, car la micro-moyenne pondère chaque classe en fonction de sa taille. Cela signifie que les classes plus fréquentes auront un impact plus important sur le score F1 avec micro-moyenne, tandis que la macro-moyenne traite chaque classe de manière égale. Il est a noté que la micro moyenne correspond souvent à l'accuracy comme nous l'avons appris en classe.\n",
    "  Voir: https://stackoverflow.com/questions/62792001/precision-and-recall-are-the-same-within-a-model/62792607#comment126263935_62792607 comme indiqué: \"in classification tasks where every test case is guaranteed to be assigned to exactly one class, computing a micro average is equivalent to computing the accuracy score\"\n",
    "\n",
    "- e) Les scores F1 observés dans nos résultat présentent une variation significative, allant de 0.139 (pour le dummy) à 0.284 (pour le random forest). Cette diversité de performances indique une sensibilité aux différentes méthodes d'imputation des valeurs manquantes et d'algorithmes de classification. Ces résultats suggèrent que certaines approches sont plus efficaces que d'autres pour résoudre notre tâche de classification.\n",
    "\n",
    "    Cependant, les scores F1 dans l'ensemble restent relativement faibes, ce qui pourrait indiquer que notre modèle ne parvient pas à prédire efficacement les données ou que la tâche de classification est assez difficile. En effet, nous avons un nombre de classes significativement grand (DEPARTMENT_NAME) ce qui pourrait expliquer la faible performance de généralisation du modèle.\n",
    "    Le dummy classifier est utile dans la mesure où il nous permet d'établir une 'baseline' de performance et ainsi comaprer un autre classificateur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
