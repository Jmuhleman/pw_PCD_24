{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fba7dc16-489f-4a3e-9cec-ab1b054719f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_set = pd.read_csv('employee.csv', encoding='ISO-8859-1')\n",
    "# travailler sur une copie pour faire des comparaisons\n",
    "df = data_set.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c15c68ac-1058-4078-9769-36ce96146bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Calcule le nombre de valeurs manquantes selon chaque feature\n",
    "# fonction old-school, existe certainement une fonction chez pandas...\n",
    "def compute_missing_values(df):\n",
    "    list_missing_val = {}\n",
    "    col = df.columns\n",
    "    for i, k in enumerate(col):\n",
    "        list_missing_val[k] = df[k].isna().sum()\n",
    "    return list_missing_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da4df011-3f9f-4618-a9e2-0e651e942445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_box_plots(df, col):\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(35, 35))\n",
    "    axs = axs.flatten()\n",
    "    for i, col in enumerate(col):\n",
    "        sns.boxplot(y=df[col], data=df, ax=axs[i])\n",
    "    \n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "    fig.delaxes(axs[-1])\n",
    "    fig.delaxes(axs[-2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "557d932b-bbce-4349-878b-bdab98b14f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22552, 12)\n",
      "missing values\n",
      "NAME-->6\n",
      "DEPARTMENT_NAME-->6\n",
      "TITLE-->6\n",
      "REGULAR-->644\n",
      "RETRO-->22150\n",
      "OTHER-->8423\n",
      "OVERTIME-->15706\n",
      "INJURED-->21096\n",
      "DETAIL-->20493\n",
      "QUINN_EDUCATION_INCENTIVE-->21166\n",
      "TOTAL_GROSS-->6\n",
      "POSTAL-->6\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Q2 voici la taille du dataframe:\n",
    "print(df.shape)\n",
    "# Q2 voici les valeurs manquantes selon les colonnes:\n",
    "list = compute_missing_values(data_set)\n",
    "print(\"missing values\")\n",
    "for i in list:\n",
    "    print(f\"{i}-->{list[i]:d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b33adcf6-8d0a-4d06-b582-6fb4b8d85d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22546 entries, 0 to 22545\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   NAME                       22546 non-null  object\n",
      " 1   DEPARTMENT_NAME            22546 non-null  object\n",
      " 2   TITLE                      22546 non-null  object\n",
      " 3   REGULAR                    21908 non-null  object\n",
      " 4   RETRO                      402 non-null    object\n",
      " 5   OTHER                      14129 non-null  object\n",
      " 6   OVERTIME                   6846 non-null   object\n",
      " 7   INJURED                    1456 non-null   object\n",
      " 8   DETAIL                     2059 non-null   object\n",
      " 9   QUINN_EDUCATION_INCENTIVE  1386 non-null   object\n",
      " 10  TOTAL_GROSS                22546 non-null  object\n",
      " 11  POSTAL                     22546 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compte le nombre de tuples vides (toutes les features à nan)\n",
    "# df[df.isna().all(axis=1)].shape[0]\n",
    "\n",
    "# suppression des tuples vides (toutes les colonnes à NaN)\n",
    "df = df.dropna(how='all')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b2ef285-d03e-4d40-9046-91d46318c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['REGULAR', 'RETRO', 'OTHER', 'OVERTIME', 'INJURED', 'DETAIL', \n",
    "       'QUINN_EDUCATION_INCENTIVE', 'TOTAL_GROSS', 'POSTAL']\n",
    "# on remplace les , ' ou tout les trucs qui perturbent la convertion en float python.\n",
    "df[col] = df[col].replace({',': '', \"'\": ''}, regex=True)\n",
    "# on applique la converton en float\n",
    "df[col] = df[col].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52a99c6a-dc56-4750-8c84-4a316069ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# on afficher les boxplots des features numériques pour observer à quoi cela ressemble\n",
    "col = ['REGULAR', 'RETRO', 'OTHER', 'OVERTIME', 'INJURED', 'DETAIL', 'QUINN_EDUCATION_INCENTIVE', 'TOTAL_GROSS']\n",
    "\n",
    "# show_box_plots(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "321df34f-f8c4-4c97-bc47-8fa98c5c3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous séléctionnons les tuples comprenant les 5 valeurs max sur le total_gross\n",
    "# nous avons 2 tuples que nous supprimons.\n",
    "top = df.nlargest(n=2, columns=['TOTAL_GROSS']).index\n",
    "# Supprimer les lignes correspondant aux index obtenus\n",
    "df = df.drop(top)\n",
    "#show_box_plots(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0908574-9a38-42e8-aab5-d681b758b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['REGULAR', 'RETRO', 'OTHER', 'OVERTIME', 'INJURED', 'DETAIL', 'QUINN_EDUCATION_INCENTIVE', 'TOTAL_GROSS']\n",
    "target = df['DEPARTMENT_NAME']\n",
    "df = df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb05faf-7441-4ffe-a001-dbda6d3bcb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.infos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "657992e4-639f-49b4-9b3f-73ac0c1e0363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputer: Zero\n",
      "Classifier: KNN         , F1 (micro): 0.231, F1 (macro): 0.050, accuracy: 0.231\n",
      "Classifier: DecisionTree, F1 (micro): 0.258, F1 (macro): 0.062, accuracy: 0.258\n",
      "Classifier: RandomForest, F1 (micro): 0.278, F1 (macro): 0.073, accuracy: 0.278\n",
      "Imputer: Median\n",
      "Classifier: KNN         , F1 (micro): 0.234, F1 (macro): 0.051, accuracy: 0.234\n",
      "Classifier: DecisionTree, F1 (micro): 0.263, F1 (macro): 0.066, accuracy: 0.263\n",
      "Classifier: RandomForest, F1 (micro): 0.279, F1 (macro): 0.074, accuracy: 0.279\n",
      "Imputer: KNN\n",
      "Classifier: KNN         , F1 (micro): 0.228, F1 (macro): 0.051, accuracy: 0.228\n",
      "Classifier: DecisionTree, F1 (micro): 0.241, F1 (macro): 0.060, accuracy: 0.241\n",
      "Classifier: RandomForest, F1 (micro): 0.267, F1 (macro): 0.064, accuracy: 0.267\n",
      "Imputer: Iterative\n",
      "Classifier: KNN         , F1 (micro): 0.238, F1 (macro): 0.051, accuracy: 0.238\n",
      "Classifier: DecisionTree, F1 (micro): 0.255, F1 (macro): 0.072, accuracy: 0.255\n",
      "Classifier: RandomForest, F1 (micro): 0.270, F1 (macro): 0.065, accuracy: 0.270\n",
      "Dummy time -> f1 micro: 0.139, f1 macro: 0.001, accuracy: 0.139\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.1, random_state=42)\n",
    "\n",
    "# Imputation des valeurs manquantes\n",
    "imputers = {\n",
    "    \"Zero\": SimpleImputer(strategy=\"constant\", fill_value=0),\n",
    "    \"Median\": SimpleImputer(strategy=\"median\"),\n",
    "    \"KNN\": KNNImputer(),\n",
    "    \"Iterative\": IterativeImputer()\n",
    "}\n",
    "\n",
    "imputed_data_train = {}\n",
    "imputed_data_test = {}\n",
    "\n",
    "for imputer_name, imputer in imputers.items():\n",
    "    # Imputer sur les données d'entraînement\n",
    "    X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "    imputed_data_train[imputer_name] = X_train_imputed\n",
    "    \n",
    "    # Imputer sur les données de test\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "    imputed_data_test[imputer_name] = X_test_imputed\n",
    "\n",
    "classifiers = {\n",
    "    \"KNN         \": KNeighborsClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for imputer_name in imputers.keys():\n",
    "    print(f\"Imputer: {imputer_name}\")\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(imputed_data_train[imputer_name], y_train)\n",
    "        \n",
    "        y_pred = clf.predict(imputed_data_test[imputer_name])\n",
    "        \n",
    "        f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        accu = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Classifier: {clf_name}, F1 (micro): {f1_micro:.3f}, F1 (macro): {f1_macro:.3f}, accuracy: {accu:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "\n",
    "accu_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "f1_dummy_mi = f1_score(y_test, y_pred_dummy, average='micro')\n",
    "f1_dummy_ma = f1_score(y_test, y_pred_dummy, average='macro')\n",
    "print(f\"Dummy time -> f1 micro: {f1_dummy_mi:.3f}, f1 macro: {f1_dummy_ma:.3f}, accuracy: {accu_dummy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c17e9-2931-487e-aee1-d8618e4abbfd",
   "metadata": {},
   "source": [
    "Median + RandomForest = meilleure micro-moyenne\n",
    "accuracy est similaire à la micro moyenne\n",
    "    voir -> https://stackoverflow.com/questions/62792001/precision-and-recall-are-the-same-within-a-model/62792607#comment126263935_62792607"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2494efac-d1c0-44eb-9d8c-42dc755eec81",
   "metadata": {},
   "source": [
    "# Rapport\n",
    "\n",
    "## Q6\n",
    "Selon doc scikit learn -> incompatible avec les classificateurs\n",
    "Selon GTP -> oui \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Q7:\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
